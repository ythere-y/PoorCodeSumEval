{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sympy import root\n",
    "from tree_sitter import Language, Parser, Node\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "from statistics import python_dict, java_dict, go_dict\n",
    "from tqdm.notebook import tqdm\n",
    "from colorama import Fore, Back, Style\n",
    "import pandas as pd\n",
    "import javalang\n",
    "\n",
    "from process_data.RobustCodeSumGo import GoParser\n",
    "import parso\n",
    "\n",
    "from utils import ParserUtils,DataUtils\n",
    "import os\n",
    "\n",
    "os.chdir(\"/data2/huchao/11.novels/bigcode-evaluation-harness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huchao/micromamba/lib/python3.9/site-packages/datasets/load.py:922: FutureWarning: The repository for code_x_glue_ct_code_to_text contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at /data2/huchao/11.novels/download/code_x_glue_ct_code_to_text/code_x_glue_ct_code_to_text.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from code search net, size: (8122, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATASET_PATH = \"/data2/huchao/11.novels/download/code_x_glue_ct_code_to_text\"\n",
    "\n",
    "dataset = load_dataset(DATASET_PATH, \"go\")[\"test\"]\n",
    "print(f\"load data from code search net, size: {dataset.shape}\")\n",
    "self_lang_str = \"go\"\n",
    "self_langurage = Language(\"/data2/huchao/11.novels/bigcode-evaluation-harness/process_data/build/my-languages.so\", self_lang_str)\n",
    "self_parser = Parser()\n",
    "self_parser.set_language(self_langurage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNE: 替换函数名为v0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// pick picks a chan for sending the given message. The picked chan and the picked chan\n",
      "// string name are returned.\n",
      "pick picks a chan for sending the given message . The picked chan and the picked chan string name are returned .\n",
      "\u001b[33mbefore handle:\u001b[39m\n",
      "func (p *peer) pick(m raftpb.Message) (writec chan<- raftpb.Message, picked string) {\n",
      "\tvar ok bool\n",
      "\t// Considering MsgSnap may have a big size, e.g., 1G, and will block\n",
      "\t// stream for a long time, only use one of the N pipelines to send MsgSnap.\n",
      "\tif isMsgSnap(m) {\n",
      "\t\treturn p.pipeline.msgc, pipelineMsg\n",
      "\t} else if writec, ok = p.msgAppV2Writer.writec(); ok && isMsgApp(m) {\n",
      "\t\treturn writec, streamAppV2\n",
      "\t} else if writec, ok = p.writer.writec(); ok {\n",
      "\t\treturn writec, streamMsg\n",
      "\t}\n",
      "\treturn p.pipeline.msgc, pipelineMsg\n",
      "}\n",
      "\u001b[32mafter handle:\u001b[39m\n",
      "func (p *peer) v0(m raftpb.Message) (writec chan<- raftpb.Message, picked string) {\n",
      "\tvar ok bool\n",
      "\t// Considering MsgSnap may have a big size, e.g., 1G, and will block\n",
      "\t// stream for a long time, only use one of the N pipelines to send MsgSnap.\n",
      "\tif isMsgSnap(m) {\n",
      "\t\treturn p.pipeline.msgc, pipelineMsg\n",
      "\t} else if writec, ok = p.msgAppV2Writer.writec(); ok && isMsgApp(m) {\n",
      "\t\treturn writec, streamAppV2\n",
      "\t} else if writec, ok = p.writer.writec(); ok {\n",
      "\t\treturn writec, streamMsg\n",
      "\t}\n",
      "\treturn p.pipeline.msgc, pipelineMsg\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "row = dataset[10]\n",
    "code_string = row[\"code\"]\n",
    "doc_string = row['docstring']\n",
    "print(doc_string)\n",
    "doc_tokens = row['docstring_tokens']\n",
    "print(' '.join(doc_tokens))\n",
    "# print(code_string)\n",
    "\n",
    "tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "from process_data.RobustCodeSumGo import GoParser\n",
    "\n",
    "identifier_node = GoParser.get_method_identifier_node(root_node)\n",
    "\n",
    "new_code_string = ParserUtils.replace_node_str(identifier_node, code_string, \"v0\")\n",
    "\n",
    "DataUtils.display_before_and_after(code_string, new_code_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataUtils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m identifier_node \u001b[38;5;241m=\u001b[39m GoParser\u001b[38;5;241m.\u001b[39mget_method_identifier_node(root_node)\n\u001b[1;32m      5\u001b[0m new_code_string \u001b[38;5;241m=\u001b[39m ParserUtils\u001b[38;5;241m.\u001b[39mreplace_node_str(identifier_node,code_string,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mDataUtils\u001b[49m\u001b[38;5;241m.\u001b[39mdisplay_before_and_after(code_string,new_code_string)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataUtils' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOS：计算交换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_video_url_from_video_id(video_id):\n",
      "    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n",
      "    # from js\n",
      "    data = [\"\"] * 256\n",
      "    for index, _ in enumerate(data):\n",
      "        t = index\n",
      "        for i in range(8):\n",
      "            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n",
      "        data[index] = t\n",
      "\n",
      "    def tmp():\n",
      "        rand_num = random.random()\n",
      "        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n",
      "                                                                              random_num=str(rand_num)[2:])\n",
      "        e = o = r = -1\n",
      "        i, a = 0, len(path)\n",
      "        while i < a:\n",
      "            e = ord(path[i])\n",
      "            i += 1\n",
      "            if e < 128:\n",
      "                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n",
      "            else:\n",
      "                if e < 2048:\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "                else:\n",
      "                    if 55296 <= e < 57344:\n",
      "                        e = (1023 & e) + 64\n",
      "                        i += 1\n",
      "                        o = 1023 & t.url(i)\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n",
      "                    else:\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "\n",
      "        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n",
      "\n",
      "    while 1:\n",
      "        url = tmp()\n",
      "        if url.split(\"=\")[-1][0] != \"-\":  # 参数s不能为负数\n",
      "            return url\n"
     ]
    }
   ],
   "source": [
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[10]\n",
    "code_string = row[\"code\"]\n",
    "print(code_string)\n",
    "\n",
    "parsed_ast = parso.parse(code_string)\n",
    "if len(list(parsed_ast.iter_funcdefs())) == 0:\n",
    "    # continue\n",
    "    exit(0)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "identifier_name_to_nodes = PythonParsoParser.get_all_identifers(func_node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_code_string = func_node.get_code()\n",
    "# print(new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRS: 随机调换标识符名字（使用函数片段中已有的标识符名字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewSTM, c, apply, so, opts, ctx, c, _, f, so, f, opts, len, opts, f, apply, apply, s, s, opts, f, s, runSTM, mkSTM, c, opts, apply, ********************\n",
      "['NewSTM', 'c', 'apply', 'so', 'opts', 'f', 's']\n",
      "********************\n",
      "\u001b[33mbefore handle:\u001b[39m\n",
      "func NewSTM(c *v3.Client, apply func(STM) error, so ...stmOption) (*v3.TxnResponse, error) {\n",
      "\topts := &stmOptions{ctx: c.Ctx()}\n",
      "\tfor _, f := range so {\n",
      "\t\tf(opts)\n",
      "\t}\n",
      "\tif len(opts.prefetch) != 0 {\n",
      "\t\tf := apply\n",
      "\t\tapply = func(s STM) error {\n",
      "\t\t\ts.Get(opts.prefetch...)\n",
      "\t\t\treturn f(s)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn runSTM(mkSTM(c, opts), apply)\n",
      "}\n",
      "\u001b[32mafter handle:\u001b[39m\n",
      "func c(apply *v3.Client, so func(STM) error, opts ...stmOption) (*v3.TxnResponse, error) {\n",
      "\tf := &stmOptions{ctx: apply.Ctx()}\n",
      "\tfor _, s := range opts {\n",
      "\t\ts(f)\n",
      "\t}\n",
      "\tif len(f.prefetch) != 0 {\n",
      "\t\ts := so\n",
      "\t\tso = func(NewSTM STM) error {\n",
      "\t\t\tNewSTM.Get(f.prefetch...)\n",
      "\t\t\treturn s(NewSTM)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn runSTM(mkSTM(apply, f), so)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的identifier_list\n",
    "# 打乱ide_list的顺序，然后形成对应，确定替换关系(ide -> ide')\n",
    "# 在code中替换对象，作为混淆结果\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "from process_data.utils import DataUtils\n",
    "\n",
    "row = dataset[0]\n",
    "code_string = row[\"code\"]\n",
    "\n",
    "tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "\n",
    "# 使用traverse方法来获取所有的identifier\n",
    "all_ide_list = []\n",
    "ParserUtils.traverse_type(root_node, all_ide_list, \"identifier\")\n",
    "\n",
    "for _ide in all_ide_list:\n",
    "    print(_ide.text.decode(\"utf8\"), end=\", \")\n",
    "print(\"*\" * 20)\n",
    "# 继承原来的方法来获取所有对象identifier（主要是要筛去api调用之类的）\n",
    "target_ide_name_list = GoParser.get_all_target_ide_name(root_node)\n",
    "print(target_ide_name_list)\n",
    "print(\"*\" * 20)\n",
    "\n",
    "# 两者结合得到所有的name和node对应关系\n",
    "identifier_dict = {}\n",
    "for _ide in all_ide_list:\n",
    "    _name = _ide.text.decode(\"utf8\")\n",
    "    if _name in target_ide_name_list:\n",
    "        if not _name in identifier_dict:\n",
    "            identifier_dict[_name] = [_ide]\n",
    "        else:\n",
    "            identifier_dict[_name].append(_ide)\n",
    "\n",
    "# 生成替换字典\n",
    "# 匹配,使用zip，使用循环替换的方法来做到打乱效果\n",
    "replace_dict = dict(zip(target_ide_name_list[:-1], target_ide_name_list[1:]))\n",
    "replace_dict.update({target_ide_name_list[-1]: target_ide_name_list[0]})\n",
    "\n",
    "\n",
    "# 替换identifier\n",
    "nodes_info = []\n",
    "for identifier, replace_str in replace_dict.items():\n",
    "    nodes = identifier_dict[identifier]\n",
    "    for node in nodes:\n",
    "        nodes_info.append((node, replace_str))\n",
    "new_code_string = ParserUtils.replace_nodes_str(nodes_info, code_string)\n",
    "\n",
    "\n",
    "DataUtils.display_before_and_after(code_string, new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHR：使用代码高频词替换标识符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mbefore handle:\u001b[39m\n",
      "func (s *levelHandler) deleteTables(toDel []*table.Table) error {\n",
      "\ts.Lock() // s.Unlock() below\n",
      "\n",
      "\ttoDelMap := make(map[uint64]struct{})\n",
      "\tfor _, t := range toDel {\n",
      "\t\ttoDelMap[t.ID()] = struct{}{}\n",
      "\t}\n",
      "\n",
      "\t// Make a copy as iterators might be keeping a slice of tables.\n",
      "\tvar newTables []*table.Table\n",
      "\tfor _, t := range s.tables {\n",
      "\t\t_, found := toDelMap[t.ID()]\n",
      "\t\tif !found {\n",
      "\t\t\tnewTables = append(newTables, t)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\ts.totalSize -= t.Size()\n",
      "\t}\n",
      "\ts.tables = newTables\n",
      "\n",
      "\ts.Unlock() // Unlock s _before_ we DecrRef our tables, which can be slow.\n",
      "\n",
      "\treturn decrRefs(toDel)\n",
      "}\n",
      "\u001b[32mafter handle:\u001b[39m\n",
      "func (q *levelHandler) deleteTables(tx []*table.Table) error {\n",
      "\tq.Lock() // s.Unlock() below\n",
      "\n",
      "\tb := make(map[uint64]struct{})\n",
      "\tfor res, t := range tx {\n",
      "\t\tb[t.ID()] = struct{}{}\n",
      "\t}\n",
      "\n",
      "\t// Make a copy as iterators might be keeping a slice of tables.\n",
      "\tvar newTables []*table.Table\n",
      "\tfor res, t := range q.tables {\n",
      "\t\tres, err := b[t.ID()]\n",
      "\t\tif !err {\n",
      "\t\t\tnewTables = append(newTables, t)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tq.totalSize -= t.Size()\n",
      "\t}\n",
      "\tq.tables = newTables\n",
      "\n",
      "\tq.Unlock() // Unlock s _before_ we DecrRef our tables, which can be slow.\n",
      "\n",
      "\treturn decrRefs(tx)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的identifier_list\n",
    "# 对于每一个目标ide,去高频词库中随机找一个词出来替换(ide,random_word)\n",
    "# 同时不同ide的替换词不能相同\n",
    "# 在code中替换对象，作为混淆结果\n",
    "\n",
    "\n",
    "# 找到所有的identifier_list\n",
    "# 打乱ide_list的顺序，然后形成对应，确定替换关系(ide -> ide')\n",
    "# 在code中替换对象，作为混淆结果\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "from process_data.utils import DataUtils\n",
    "\n",
    "\n",
    "row = dataset[784]\n",
    "code_string = row[\"code\"]\n",
    "\n",
    "tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "\n",
    "# 使用traverse方法来获取所有的identifier\n",
    "all_ide_list = []\n",
    "ParserUtils.traverse_type(root_node, all_ide_list, \"identifier\")\n",
    "\n",
    "# 继承原来的方法来获取所有对象identifier（主要是要筛去api调用之类的）\n",
    "target_ide_name_list = GoParser.get_all_target_ide_name(root_node)\n",
    "\n",
    "# 两者结合得到所有的name和node对应关系\n",
    "identifier_dict = {}\n",
    "for _ide in all_ide_list:\n",
    "    _name = _ide.text.decode(\"utf8\")\n",
    "    if _name in target_ide_name_list:\n",
    "        if not _name in identifier_dict:\n",
    "            identifier_dict[_name] = [_ide]\n",
    "        else:\n",
    "            identifier_dict[_name].append(_ide)\n",
    "\n",
    "\n",
    "# 获取高频词数组\n",
    "high_freq_list = [word[0] for word in go_dict]\n",
    "\n",
    "\n",
    "# 对所有identifier随机匹配一个高频词，且不能有重复的\n",
    "# 做法是，先shuffle high_freq_dict，然后按顺序匹配\n",
    "\n",
    "# shuffle\n",
    "random.shuffle(high_freq_list)\n",
    "\n",
    "# 使用匹配的方式，生成替换字典\n",
    "replace_dict = {}\n",
    "for identifier in target_ide_name_list:\n",
    "    replace_dict[identifier] = high_freq_list.pop()\n",
    "\n",
    "\n",
    "# 替换identifier\n",
    "nodes_info = []\n",
    "for identifier, replace_str in replace_dict.items():\n",
    "    nodes = identifier_dict[identifier]\n",
    "    for node in nodes:\n",
    "        nodes_info.append((node, replace_str))\n",
    "new_code_string = ParserUtils.replace_nodes_str(nodes_info, code_string)\n",
    "\n",
    "\n",
    "DataUtils.display_before_and_after(code_string, new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOE:标识符变成v0，v1…，函数名也会变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mbefore handle:\u001b[39m\n",
      "private static boolean overrides(Method a, Method b) {\n",
      "    // See JLS section 8.4.8.1\n",
      "    int modifiers = b.getModifiers();\n",
      "    if (Modifier.isPublic(modifiers) || Modifier.isProtected(modifiers)) {\n",
      "      return true;\n",
      "    }\n",
      "    if (Modifier.isPrivate(modifiers)) {\n",
      "      return false;\n",
      "    }\n",
      "    // b must be package-private\n",
      "    return a.getDeclaringClass().getPackage().equals(b.getDeclaringClass().getPackage());\n",
      "  }\n",
      "\u001b[32mafter handle:\u001b[39m\n",
      "ic boolean v0(Method v1, Method v2) {\n",
      "    // See JLS section 8.4.8.1\n",
      "    int v3 = v2.getModifiers();\n",
      "    if (Modifier.isPublic(v3) || Modifier.isProtected(v3)) {\n",
      "      return true;\n",
      "    }\n",
      "    if (Modifier.isPrivate(v3)) {\n",
      "      return false;\n",
      "    }\n",
      "    // b must be package-private\n",
      "    return v1.getDeclaringClass().getPackage().equals(v2.getDeclaringClass().getPackage());\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 找到所有的identifier_list\n",
    "# 将其中的100%作为替换目标\n",
    "# 替换identifier_list，每个ide给予一个对象(v_n)\n",
    "# 在code中替换对象，作为混淆结果\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "from process_data.utils import DataUtils\n",
    "\n",
    "row = dataset[323]\n",
    "code_string = row[\"code\"]\n",
    "# print(code_string)\n",
    "\n",
    "tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "\n",
    "# 使用traverse方法来获取所有的identifier\n",
    "all_ide_list = []\n",
    "ParserUtils.traverse_type(root_node, all_ide_list, \"identifier\")\n",
    "# for _ide in all_ide_list:\n",
    "#     print(_ide.text.decode(\"utf8\"))\n",
    "# 继承原来的方法来获取所有对象identifier（主要是要筛去api调用之类的）\n",
    "target_ide_name_list = []\n",
    "nodes = [root_node]\n",
    "while len(nodes) > 0:\n",
    "    cur_node = nodes.pop(0)\n",
    "    if cur_node.type == \"ERROR\":\n",
    "        print(code_string)\n",
    "        continue\n",
    "\n",
    "    if (\n",
    "        cur_node.type == \"variable_declarator\"\n",
    "        or cur_node.type == \"formal_parameter\"\n",
    "        or cur_node.type == \"method_declaration\"\n",
    "        or cur_node.type == \"constructor_declaration\"\n",
    "        or cur_node.type == \"assignment_expression\"\n",
    "    ):\n",
    "        for child in cur_node.children:\n",
    "            if child.type == \"identifier\":\n",
    "                identifier_string = child.text.decode(\"utf8\")\n",
    "                if not identifier_string in target_ide_name_list:\n",
    "                    target_ide_name_list.append(identifier_string)\n",
    "    for child in cur_node.children:\n",
    "        nodes.append(child)\n",
    "\n",
    "# 两者结合得到所有的name和node对应关系\n",
    "identifier_dict = {}\n",
    "for _ide in all_ide_list:\n",
    "    _name = _ide.text.decode(\"utf8\")\n",
    "    if _name in target_ide_name_list:\n",
    "        if not _name in identifier_dict:\n",
    "            identifier_dict[_name] = [_ide]\n",
    "        else:\n",
    "            identifier_dict[_name].append(_ide)\n",
    "# for key in identifier_dict:\n",
    "#     print(key, len(identifier_dict[key]))\n",
    "\n",
    "# 生成替换字典\n",
    "replace_dict = {}\n",
    "for i, ide_name in enumerate(target_ide_name_list):\n",
    "    replace_dict[ide_name] = f\"v{i}\"\n",
    "\n",
    "# 替换identifier\n",
    "nodes_info = []\n",
    "for identifier, replace_str in replace_dict.items():\n",
    "    nodes = identifier_dict[identifier]\n",
    "    for node in nodes:\n",
    "        nodes_info.append((node, replace_str))\n",
    "new_code_string = ParserUtils.replace_nodes_str(nodes_info, code_string)\n",
    "DataUtils.display_before_and_after(code_string, new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HVI:加入无意义的高频次的变量声明\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func (r *raft) bcastAppend() {\n",
      "\tr.forEachProgress(func(id uint64, _ *Progress) {\n",
      "\t\tif id == r.id {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\n",
      "\t\tr.sendAppend(id)\n",
      "\t})\n",
      "}\n",
      "insert node = b'r.forEachProgress(func(id uint64, _ *Progress) {\\n\\t\\tif id == r.id {\\n\\t\\t\\treturn\\n\\t\\t}\\n\\n\\t\\tr.sendAppend(id)\\n\\t})'\n",
      "insert indent = 4\n",
      "    var i int = 96\n",
      "    var value int = 12\n",
      "    var result int = 79\n",
      "insert line number = 1\n",
      "\u001b[33mbefore handle:\u001b[39m\n",
      "func (r *raft) bcastAppend() {\n",
      "\tr.forEachProgress(func(id uint64, _ *Progress) {\n",
      "\t\tif id == r.id {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\n",
      "\t\tr.sendAppend(id)\n",
      "\t})\n",
      "}\n",
      "\u001b[32mafter handle:\u001b[39m\n",
      "func (r *raft) bcastAppend() {\n",
      "    var i int = 96\n",
      "    var value int = 12\n",
      "    var result int = 79\n",
      "\tr.forEachProgress(func(id uint64, _ *Progress) {\n",
      "\t\tif id == r.id {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\n",
      "\t\tr.sendAppend(id)\n",
      "\t})\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from process_data.utils import DataUtils\n",
    "\n",
    "row = dataset[54]\n",
    "code_string = row[\"code\"]\n",
    "\n",
    "print(code_string)\n",
    "\n",
    "tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "\n",
    "\n",
    "# 继承原来的方法来获取所有对象identifier（主要是要筛去api调用之类的）\n",
    "target_ide_name_list = GoParser.get_all_target_ide_name(root_node)\n",
    "\n",
    "\n",
    "insert_list = []\n",
    "insert_num = 3\n",
    "for i in range(len(java_dict)):\n",
    "    if not java_dict[i][0] in target_ide_name_list:\n",
    "        insert_list.append(java_dict[i][0])\n",
    "        if len(insert_list) == insert_num:\n",
    "            break\n",
    "\n",
    "func_body_node = GoParser.get_method_body_node(root_node)\n",
    "candidates_list = []\n",
    "for node in func_body_node.children:\n",
    "    if len(node.type) > 2:\n",
    "        candidates_list.append(node)\n",
    "insert_node = random.choice(candidates_list)\n",
    "print(f\"insert node = {insert_node.text}\")\n",
    "\n",
    "# 插入在这个child的前面\n",
    "# 获取这个位置的缩进\n",
    "insert_indent_count = ParserUtils.get_node_indent_count(insert_node, code_string)\n",
    "print(f\"insert indent = {insert_indent_count}\")\n",
    "\n",
    "\n",
    "# 制作插入体\n",
    "insert_str = \"\"\n",
    "for var in insert_list:\n",
    "    insert_str += f\"{' '*insert_indent_count}var {var} int = {random.randint(0,100)}\\n\"\n",
    "# 最后的位置去掉换行\n",
    "insert_str = insert_str[:-1]\n",
    "print(insert_str)\n",
    "\n",
    "\n",
    "# 获取这个位置的行号\n",
    "insert_position = insert_node.start_point[0]\n",
    "print(f\"insert line number = {insert_position}\")\n",
    "\n",
    "# 进行插入\n",
    "body_code_lines = code_string.split(\"\\n\")\n",
    "body_code_lines.insert(insert_position, insert_str)\n",
    "new_code_string = \"\\n\".join(body_code_lines)\n",
    "\n",
    "DataUtils.display_before_and_after(code_string, new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测这样获取method body的方法是否总是成功\n",
    "\n",
    "结果是总是成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for row in dataset:\n",
    "    code_string = row[\"code\"]\n",
    "    code_string = JavaParser.wrap_java_code(code_string)\n",
    "\n",
    "    tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "    root_node = tree.root_node\n",
    "    func_body_node = (\n",
    "        root_node.children[0].children[-1].children[1].child_by_field_name(\"body\")\n",
    "    )\n",
    "    if func_body_node == None:\n",
    "        print(\"error~!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBI:插入死分支\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx = 3014\n",
      "func NotNil(tb testing.TB, object interface{}, msgAndArgs ...interface{}) {\n",
      "\ttb.Helper()\n",
      "\tsuccess := true\n",
      "\n",
      "\tif object == nil {\n",
      "\t\tsuccess = false\n",
      "\t} else {\n",
      "\t\tvalue := reflect.ValueOf(object)\n",
      "\t\tkind := value.Kind()\n",
      "\t\tif kind >= reflect.Chan && kind <= reflect.Slice && value.IsNil() {\n",
      "\t\t\tsuccess = false\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tif !success {\n",
      "\t\tfatal(tb, msgAndArgs, \"Expected value not to be nil.\")\n",
      "\t}\n",
      "}\n",
      "{\n",
      "\ttb.Helper()\n",
      "\tsuccess := true\n",
      "\n",
      "\tif object == nil {\n",
      "\t\tsuccess = false\n",
      "\t} else {\n",
      "\t\tvalue := reflect.ValueOf(object)\n",
      "\t\tkind := value.Kind()\n",
      "\t\tif kind >= reflect.Chan && kind <= reflect.Slice && value.IsNil() {\n",
      "\t\t\tsuccess = false\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tif !success {\n",
      "\t\tfatal(tb, msgAndArgs, \"Expected value not to be nil.\")\n",
      "\t}\n",
      "}\n",
      "insert indent = 4\n",
      "b'\\n        return storeTrustedKey(ks.LocalRootPath, r)'\n",
      "18 18\n",
      "19 18\n",
      "\u001b[33mbefore handle:\u001b[39m\n",
      "func NotNil(tb testing.TB, object interface{}, msgAndArgs ...interface{}) {\n",
      "\ttb.Helper()\n",
      "\tsuccess := true\n",
      "\n",
      "\tif object == nil {\n",
      "\t\tsuccess = false\n",
      "\t} else {\n",
      "\t\tvalue := reflect.ValueOf(object)\n",
      "\t\tkind := value.Kind()\n",
      "\t\tif kind >= reflect.Chan && kind <= reflect.Slice && value.IsNil() {\n",
      "\t\t\tsuccess = false\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tif !success {\n",
      "\t\tfatal(tb, msgAndArgs, \"Expected value not to be nil.\")\n",
      "\t}\n",
      "}\n",
      "\u001b[32mafter handle:\u001b[39m\n",
      "func NotNil(tb testing.TB, object interface{}, msgAndArgs ...interface{}) {\n",
      "    if true {\n",
      "    \ttb.Helper()\n",
      "    \tsuccess := true\n",
      "    \n",
      "    \tif object == nil {\n",
      "    \t\tsuccess = false\n",
      "    \t} else {\n",
      "    \t\tvalue := reflect.ValueOf(object)\n",
      "    \t\tkind := value.Kind()\n",
      "    \t\tif kind >= reflect.Chan && kind <= reflect.Slice && value.IsNil() {\n",
      "    \t\t\tsuccess = false\n",
      "    \t\t}\n",
      "    \t}\n",
      "    \n",
      "    \tif !success {\n",
      "    \t\tfatal(tb, msgAndArgs, \"Expected value not to be nil.\")\n",
      "    \t}\n",
      "    }\n",
      "    else {\n",
      "        return storeTrustedKey(ks.LocalRootPath, r)\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from numpy import insert\n",
    "from process_data.utils import DataUtils\n",
    "\n",
    "print(f\"idx = {test_idx}\")\n",
    "row = dataset[test_idx]\n",
    "test_idx += 100\n",
    "\n",
    "code_string = row[\"code\"]\n",
    "print(code_string)\n",
    "\n",
    "tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "func_body_node = root_node.children[0].child_by_field_name(\"body\")\n",
    "print(func_body_node.text.decode(\"utf8\"))\n",
    "\n",
    "# print(func_body_node.text.decode(\"utf8\"))\n",
    "\n",
    "insert_indent_count = 4\n",
    "print(f\"insert indent = {insert_indent_count}\")\n",
    "\n",
    "insert_body = DataUtils.get_dead_if_body(\"go\", \" \" * insert_indent_count)\n",
    "print(insert_body.encode())\n",
    "# print(insert_body)\n",
    "\n",
    "\n",
    "# 给原body做缩进\n",
    "code_lines = code_string.split(\"\\n\")\n",
    "## 确定起始位置\n",
    "move_start_line = func_body_node.start_point[0] + 1\n",
    "move_end_line = func_body_node.end_point[0] + 1\n",
    "## 加tab移动\n",
    "for i in range(move_start_line, move_end_line):\n",
    "    code_lines[i] = \"    \" + code_lines[i]\n",
    "\n",
    "random_case = random.randint(0, 1)\n",
    "random_case = 0\n",
    "if random_case == 0:\n",
    "    # 插入 if true & else\n",
    "    if_stmt = f\"{' '*insert_indent_count}if true {{\"\n",
    "    code_lines.insert(move_start_line, if_stmt)\n",
    "    else_stmt = f'{\" \" *insert_indent_count}else {{{insert_body}\\n{\" \"*insert_indent_count}}}\\n}}'\n",
    "    print(len(code_lines), move_end_line)\n",
    "    code_lines.insert(move_end_line + 1, else_stmt)\n",
    "else:\n",
    "    ## 插入 if false & else\n",
    "    front_stmt = f\"{' '*insert_indent_count}if false {{{insert_body}\\n{' '*insert_indent_count}}} else {{\"\n",
    "    code_lines.insert(move_start_line, front_stmt)\n",
    "    code_lines.insert(move_end_line + 2, \"}\")\n",
    "# print(\"\\n\".join(code_lines))\n",
    "new_code_string = \"\\n\".join(code_lines)\n",
    "DataUtils.display_before_and_after(code_string, new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查body最后的}是不是独立成行\n",
    "\n",
    "结论：所有数据的最后一个}都是独立成行的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 检查body最后的}是不是独立成行\n",
    "\n",
    "for idx, row in enumerate(dataset):\n",
    "    code_string = row[\"code\"]\n",
    "    tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "    root_node = tree.root_node\n",
    "    func_body_node = root_node.children[0].child_by_field_name(\"body\")\n",
    "    body_code_string = func_body_node.text.decode(\"utf8\")\n",
    "\n",
    "    body_code_lines = body_code_string.split(\"\\n\")\n",
    "    last_line = body_code_lines[-1]\n",
    "    last_line_strip = last_line.replace(\"}\", \" \").strip()\n",
    "    if last_line_strip != \"\":\n",
    "        print(f\"idx = {idx}\")\n",
    "        print(last_line.encode())\n",
    "        # print(sttp.encode())\n",
    "        # print(func_body_node.text.decode(\"utf8\"))\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查body开头的{的问题\n",
    "\n",
    "结论：所有数据的开头的{都是独立成行的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(dataset):\n",
    "    code_string = row[\"code\"]\n",
    "    tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "    root_node = tree.root_node\n",
    "    func_body_node = root_node.children[0].child_by_field_name(\"body\")\n",
    "    body_code_string = func_body_node.text.decode(\"utf8\")\n",
    "    body_code_lines = body_code_string.split(\"\\n\")\n",
    "    first_line = body_code_lines[0]\n",
    "    first_strip = first_line.strip()\n",
    "    if first_strip != \"{\":\n",
    "        print(f\"idx = {idx}\")\n",
    "        print(first_strip.encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parso Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n",
      "\t    rawurl = []\n",
      "\t    dom = parseString(xml_data)\n",
      "\t    for node in dom.getElementsByTagName('durl'):\n",
      "\t        url = node.getElementsByTagName('url')[0]\n",
      "\t        rawurl.append(url.childNodes[0].data)\n",
      "\t    return rawurl\n"
     ]
    }
   ],
   "source": [
    "import parso\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[0]\n",
    "# print(row[\"code\"])\n",
    "code = row[\"code\"]\n",
    "parsed_ast = parso.parse(code, error_recovery=False, version=\"3.7\")\n",
    "code_tokens, comment_tokens = [], []\n",
    "\n",
    "func_nodes = list(parsed_ast.iter_funcdefs())\n",
    "\n",
    "func_node = func_nodes[0]\n",
    "doc_node = func_node.get_doc_node()\n",
    "\n",
    "body_block = PythonParsoParser.find_function_body_block(func_node)\n",
    "body_block_string = PythonParsoParser.get_body_block_string(body_block)\n",
    "# 每一行加一个\\t\n",
    "body_block_string = \"\\t\" + body_block_string.replace(\"\\n\", \"\\n\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试从输出位置load data文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14917, 12)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from datasets import load_dataset,load_from_disk\n",
    "\n",
    "reload_data = load_from_disk('../local_data/second/semantic/IRS/python/CSN')\n",
    "print(reload_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "async def renew_lock(self):\n",
    "    \"\"\"Renew the message lock.\n",
    "\n",
    "    This will maintain the lock on the message to ensure\n",
    "    it is not returned to the queue to be reprocessed. In order to complete (or otherwise settle)\n",
    "    the message, the lock must be maintained. Messages received via ReceiveAndDelete mode are not\n",
    "    locked, and therefore cannot be renewed. This operation can also be performed as an asynchronous\n",
    "    background task by registering the message with an `azure.servicebus.aio.AutoLockRenew` instance.\n",
    "    This operation is only available for non-sessionful messages.\n",
    "\n",
    "    :raises: TypeError if the message is sessionful.\n",
    "    :raises: ~azure.servicebus.common.errors.MessageLockExpired is message lock has already expired.\n",
    "    :raises: ~azure.servicebus.common.errors.SessionLockExpired if session lock has already expired.\n",
    "    :raises: ~azure.servicebus.common.errors.MessageAlreadySettled is message has already been settled.\n",
    "    \"\"\"\n",
    "    if hasattr(self._receiver, \"locked_until\"):\n",
    "        raise TypeError(\n",
    "            \"Session messages cannot be renewed. Please renew the Session lock instead.\"\n",
    "        )\n",
    "    self._is_live(\"renew\")\n",
    "    expiry = await self._receiver._renew_locks(\n",
    "        self.lock_token\n",
    "    )  # pylint: disable=protected-access\n",
    "    self._expiry = datetime.datetime.fromtimestamp(expiry[b\"expirations\"][0] / 1000.0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试删除Java注释\n",
    "\n",
    "检查后发现CodeSearchNet中的Java数据的tokens数据中也留有注释\n",
    "\n",
    "所以决定这里也不做删除注释操作了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private static boolean overrides ( Method a , Method b ) { // See JLS section 8.4.8.1 int modifiers = b . getModifiers ( ) ; if ( Modifier . isPublic ( modifiers ) || Modifier . isProtected ( modifiers ) ) { return true ; } if ( Modifier . isPrivate ( modifiers ) ) { return false ; } // b must be package-private return a . getDeclaringClass ( ) . getPackage ( ) . equals ( b . getDeclaringClass ( ) . getPackage ( ) ) ; }\n"
     ]
    }
   ],
   "source": [
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[323]\n",
    "code_string = row[\"code\"]\n",
    "code_tokens = row['code_tokens']\n",
    "print(' '.join(code_tokens))\n",
    "# print(code_string)\n",
    "\n",
    "tree = self_parser.parse(bytes(code_string, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "comments_node = []\n",
    "ParserUtils.traverse_type(root_node, comments_node, \"comment\")\n",
    "for comment in comments_node:\n",
    "    print(comment.text.decode(\"utf8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
