{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sympy import root\n",
    "from tree_sitter import Language, Parser, Node\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "from statistics import python_dict, java_dict, go_dict\n",
    "from tqdm.notebook import tqdm\n",
    "from colorama import Fore, Back, Style\n",
    "import pandas as pd\n",
    "\n",
    "import parso\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huchao/micromamba/lib/python3.9/site-packages/datasets/load.py:922: FutureWarning: The repository for code_x_glue_ct_code_to_text contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at /data2/huchao/11.novels/download/code_x_glue_ct_code_to_text/code_x_glue_ct_code_to_text.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from code search net, size: (14918, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATASET_PATH = \"/data2/huchao/11.novels/download/code_x_glue_ct_code_to_text\"\n",
    "\n",
    "dataset = load_dataset(DATASET_PATH, \"python\")[\"test\"]\n",
    "print(f\"load data from code search net, size: {dataset.shape}\")\n",
    "self_lang_str = \"python\"\n",
    "self_langurage = Language(\"/data2/huchao/11.novels/bigcode-evaluation-harness/process_data/build/my-languages.so\", self_lang_str)\n",
    "self_parser = Parser()\n",
    "self_parser.set_language(self_langurage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNE: 替换函数名为v0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_video_url_from_video_id(video_id):\n",
      "    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n",
      "    # from js\n",
      "    data = [\"\"] * 256\n",
      "    for index, _ in enumerate(data):\n",
      "        t = index\n",
      "        for i in range(8):\n",
      "            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n",
      "        data[index] = t\n",
      "\n",
      "    def tmp():\n",
      "        rand_num = random.random()\n",
      "        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n",
      "                                                                              random_num=str(rand_num)[2:])\n",
      "        e = o = r = -1\n",
      "        i, a = 0, len(path)\n",
      "        while i < a:\n",
      "            e = ord(path[i])\n",
      "            i += 1\n",
      "            if e < 128:\n",
      "                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n",
      "            else:\n",
      "                if e < 2048:\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "                else:\n",
      "                    if 55296 <= e < 57344:\n",
      "                        e = (1023 & e) + 64\n",
      "                        i += 1\n",
      "                        o = 1023 & t.url(i)\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n",
      "                    else:\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "\n",
      "        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n",
      "\n",
      "    while 1:\n",
      "        url = tmp()\n",
      "        if url.split(\"=\")[-1][0] != \"-\":  # 参数s不能为负数\n",
      "            return url\n",
      "def v0(video_id):\n",
      "    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n",
      "    # from js\n",
      "    data = [\"\"] * 256\n",
      "    for index, _ in enumerate(data):\n",
      "        t = index\n",
      "        for i in range(8):\n",
      "            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n",
      "        data[index] = t\n",
      "\n",
      "    def tmp():\n",
      "        rand_num = random.random()\n",
      "        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n",
      "                                                                              random_num=str(rand_num)[2:])\n",
      "        e = o = r = -1\n",
      "        i, a = 0, len(path)\n",
      "        while i < a:\n",
      "            e = ord(path[i])\n",
      "            i += 1\n",
      "            if e < 128:\n",
      "                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n",
      "            else:\n",
      "                if e < 2048:\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "                else:\n",
      "                    if 55296 <= e < 57344:\n",
      "                        e = (1023 & e) + 64\n",
      "                        i += 1\n",
      "                        o = 1023 & t.url(i)\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n",
      "                    else:\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "\n",
      "        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n",
      "\n",
      "    while 1:\n",
      "        url = tmp()\n",
      "        if url.split(\"=\")[-1][0] != \"-\":  # 参数s不能为负数\n",
      "            return url\n"
     ]
    }
   ],
   "source": [
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[10]\n",
    "code_string = row[\"code\"]\n",
    "print(code_string)\n",
    "\n",
    "parsed_ast = parso.parse(code_string)\n",
    "if len(list(parsed_ast.iter_funcdefs())) == 0:\n",
    "    # continue\n",
    "    exit(0)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "for child in func_node.children:\n",
    "    if child.type == 'name':\n",
    "        child.value = 'v0'\n",
    "        break\n",
    "\n",
    "new_code_string = func_node.get_code()\n",
    "print(new_code_string)\n",
    "# print(new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOS：计算交换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_video_url_from_video_id(video_id):\n",
      "    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n",
      "    # from js\n",
      "    data = [\"\"] * 256\n",
      "    for index, _ in enumerate(data):\n",
      "        t = index\n",
      "        for i in range(8):\n",
      "            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n",
      "        data[index] = t\n",
      "\n",
      "    def tmp():\n",
      "        rand_num = random.random()\n",
      "        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n",
      "                                                                              random_num=str(rand_num)[2:])\n",
      "        e = o = r = -1\n",
      "        i, a = 0, len(path)\n",
      "        while i < a:\n",
      "            e = ord(path[i])\n",
      "            i += 1\n",
      "            if e < 128:\n",
      "                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n",
      "            else:\n",
      "                if e < 2048:\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n",
      "                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "                else:\n",
      "                    if 55296 <= e < 57344:\n",
      "                        e = (1023 & e) + 64\n",
      "                        i += 1\n",
      "                        o = 1023 & t.url(i)\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n",
      "                    else:\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n",
      "                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n",
      "\n",
      "        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n",
      "\n",
      "    while 1:\n",
      "        url = tmp()\n",
      "        if url.split(\"=\")[-1][0] != \"-\":  # 参数s不能为负数\n",
      "            return url\n"
     ]
    }
   ],
   "source": [
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[10]\n",
    "code_string = row[\"code\"]\n",
    "print(code_string)\n",
    "\n",
    "parsed_ast = parso.parse(code_string)\n",
    "if len(list(parsed_ast.iter_funcdefs())) == 0:\n",
    "    # continue\n",
    "    exit(0)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "identifier_name_to_nodes = PythonParsoParser.get_all_identifers(func_node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_code_string = func_node.get_code()\n",
    "# print(new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRS: 随机调换标识符名字（使用函数片段中已有的标识符名字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n",
      "def xml_data(node):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    dom = []\n",
      "    url = parseString(xml_data)\n",
      "    for rawurl in url.getElementsByTagName('durl'):\n",
      "        sina_xml_to_url_list = rawurl.getElementsByTagName('url')[0]\n",
      "        dom.append(sina_xml_to_url_list.childNodes[0].data)\n",
      "    return dom\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的identifier_list\n",
    "# 打乱ide_list的顺序，然后形成对应，确定替换关系(ide -> ide')\n",
    "# 在code中替换对象，作为混淆结果\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[0]\n",
    "\n",
    "row = dataset[0]\n",
    "code_string = row[\"code\"]\n",
    "print(code_string)\n",
    "\n",
    "\n",
    "parsed_ast = parso.parse(code_string)\n",
    "if len(list(parsed_ast.iter_funcdefs())) == 0:\n",
    "    # continue\n",
    "    exit(0)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "identifier_name_to_nodes = PythonParsoParser.get_all_identifers(func_node)\n",
    "\n",
    "\n",
    "# 获取所有的identifier\n",
    "identifier_list = list(identifier_name_to_nodes.keys())\n",
    "\n",
    "# 匹配,使用zip，使用循环替换的方法来做到打乱效果\n",
    "replace_dict = dict(\n",
    "    zip(\n",
    "        identifier_list[:-1],identifier_list[1:]\n",
    "    )\n",
    ")\n",
    "replace_dict.update({identifier_list[-1]:identifier_list[0]})\n",
    "\n",
    "# 替换identifier\n",
    "for identifier, replace_str in replace_dict.items():\n",
    "    nodes = identifier_name_to_nodes[identifier]\n",
    "    for node in nodes:\n",
    "        node.value = replace_str\n",
    "\n",
    "\n",
    "new_code_string = func_node.get_code()\n",
    "print(new_code_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHR：使用代码高频词替换标识符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n",
      "{'sina_xml_to_url_list': 'filename', 'xml_data': 'results', 'node': 's', 'rawurl': 'i', 'dom': 'name', 'url': 'func'}\n",
      "def filename(results):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    i = []\n",
      "    name = parseString(xml_data)\n",
      "    for s in name.getElementsByTagName('durl'):\n",
      "        func = s.getElementsByTagName('url')[0]\n",
      "        i.append(func.childNodes[0].data)\n",
      "    return i\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的identifier_list\n",
    "# 对于每一个目标ide,去高频词库中随机找一个词出来替换(ide,random_word)\n",
    "# 同时不同ide的替换词不能相同\n",
    "# 在code中替换对象，作为混淆结果\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[0]\n",
    "\n",
    "row = dataset[0]\n",
    "code_string = row[\"code\"]\n",
    "print(code_string)\n",
    "\n",
    "\n",
    "parsed_ast = parso.parse(code_string)\n",
    "if len(list(parsed_ast.iter_funcdefs())) == 0:\n",
    "    # continue\n",
    "    exit(0)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "identifier_name_to_nodes = PythonParsoParser.get_all_identifers(func_node)\n",
    "\n",
    "\n",
    "# 获取高频词数组\n",
    "high_freq_list = [word[0] for word in python_dict]\n",
    "\n",
    "# 获取所有的identifier\n",
    "identifier_list = list(identifier_name_to_nodes.keys())\n",
    "\n",
    "# 对所有identifier随机匹配一个高频词，且不能有重复的\n",
    "# 做法是，先shuffle high_freq_dict，然后按顺序匹配\n",
    "\n",
    "# shuffle\n",
    "random.shuffle(high_freq_list)\n",
    "\n",
    "# 匹配\n",
    "replace_dict = {}\n",
    "for identifier in identifier_list:\n",
    "    replace_dict[identifier] = high_freq_list.pop()\n",
    "\n",
    "print(replace_dict)\n",
    "\n",
    "# 替换identifier\n",
    "\n",
    "for identifier, replace_str in replace_dict.items():\n",
    "    nodes = identifier_name_to_nodes[identifier]\n",
    "    for node in nodes:\n",
    "        node.value = replace_str\n",
    "\n",
    "print(func_node.get_code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOE:标识符变成v0，v1…，函数名也会变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n",
      "{'rawurl': 'v_0', 'xml_data': 'v_1', 'node': 'v_2', 'url': 'v_3'}\n",
      "def sina_xml_to_url_list(v_1):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    v_0 = []\n",
      "    dom = parseString(xml_data)\n",
      "    for v_2 in dom.getElementsByTagName('durl'):\n",
      "        v_3 = v_2.getElementsByTagName('url')[0]\n",
      "        v_0.append(v_3.childNodes[0].data)\n",
      "    return v_0\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的identifier_list\n",
    "# 将其中的80%作为替换目标\n",
    "# 替换identifier_list，每个ide给予一个对象(v_n)\n",
    "# 在code中替换对象，作为混淆结果\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[0]\n",
    "\n",
    "row = dataset[0]\n",
    "code_string = row[\"code\"]\n",
    "print(code_string)\n",
    "\n",
    "\n",
    "parsed_ast = parso.parse(code_string)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "identifier_name_to_nodes = PythonParsoParser.get_all_identifers(func_node)\n",
    "\n",
    "# 从identifier_name_to_nodes中随机选取80%的identifier\n",
    "# 使用random.sample\n",
    "rate = 0.8\n",
    "identifier_list = list(identifier_name_to_nodes.keys())\n",
    "final_identifier_list = random.sample(identifier_list, int(len(identifier_list) * rate))\n",
    "\n",
    "# 生成替换字典\n",
    "# 使用v_0,v_1按顺序替换\n",
    "replace_dict = {}\n",
    "for i, identifier in enumerate(final_identifier_list):\n",
    "    replace_dict[identifier] = f\"v_{i}\"\n",
    "print(replace_dict)\n",
    "\n",
    "# 替换identifier\n",
    "\n",
    "for identifier, replace_str in replace_dict.items():\n",
    "    nodes = identifier_name_to_nodes[identifier]\n",
    "    for node in nodes:\n",
    "        node.value = replace_str\n",
    "\n",
    "print(func_node.get_code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HVI:加入无意义的高频次的变量声明\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    data=26\n",
      "    name=74\n",
      "    value=25\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n"
     ]
    }
   ],
   "source": [
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "\n",
    "row = dataset[0]\n",
    "code_string = row[\"code\"]\n",
    "# print(code_string)\n",
    "\n",
    "\n",
    "parsed_ast = parso.parse(code_string)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "identifier_name_to_nodes = PythonParsoParser.get_all_identifers(func_node)\n",
    "# for key in identifier_name_to_nodes:\n",
    "#     print(f\"{key}:{len(identifier_name_to_nodes[key])}\")\n",
    "\n",
    "insert_list = []\n",
    "insert_num = 3\n",
    "for i in range(len(python_dict)):\n",
    "    if not python_dict[i][0] in identifier_name_to_nodes:\n",
    "        insert_list.append(python_dict[i][0])\n",
    "        insert_num -= 1\n",
    "    if insert_num == 0:\n",
    "        break\n",
    "\n",
    "body_node = PythonParsoParser.find_function_body_block(func_node)\n",
    "\n",
    "# 统计不是newline的node，并记录在list中\n",
    "not_newline_list = []\n",
    "for i in range(len(body_node.children)):\n",
    "    if body_node.children[i].type != \"newline\":\n",
    "        not_newline_list.append(i)\n",
    "\n",
    "# 制作一个随机数，从中选择一个位置进行插入，这个位置不能是第一个（第一个是doc）\n",
    "insert_index = random.choice(not_newline_list[1:])\n",
    "\n",
    "# 制作插入的文本insert_text\n",
    "# 获取插入位置的退格信息\n",
    "insert_indent = body_node.children[insert_index].get_first_leaf().prefix\n",
    "insert_text = \"\"\n",
    "for i in range(len(insert_list)):\n",
    "    # 插入的是变量赋值语句，值从0-100中随机生成\n",
    "    insert_text += (\n",
    "        insert_indent + insert_list[i] + f\"={random.randint(0,100)}\" + \"\\n\"\n",
    "    )\n",
    "\n",
    "# 将insert_text插入到body_node中\n",
    "body_node.children[insert_index].get_first_leaf().prefix = (\n",
    "    insert_text + insert_indent\n",
    ")\n",
    "\n",
    "# print(body_node.children[insert_index].get_first_leaf().prefix)\n",
    "# print(body_node.get_code())\n",
    "print(func_node.get_code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBI:插入死分支\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dataset[0]\n",
    "code_string = row['code']\n",
    "tree = self_parser.parse(bytes(code_string, \"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurldef sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from process_data.RobustCodeSum import Utils\n",
    "code_string = row[\"code\"]\n",
    "\n",
    "# 抽取函数的body，并加上退格\n",
    "parsed_ast = parso.parse(code_string)\n",
    "func_node = list(parsed_ast.iter_funcdefs())[0]\n",
    "body_block = PythonParsoParser.find_function_body_block(func_node)\n",
    "body_block_string = PythonParsoParser.get_body_block_string(body_block)\n",
    "# 每一行加一个退格\n",
    "body_block_string = \"    \" + body_block_string.replace(\"\\n\", \"\\n    \")\n",
    "# 获取prefix,找第一行代码，不断向下找child，直到某个child有prefix\n",
    "try:\n",
    "    base_child = func_node.children[-1].children[1]\n",
    "    while not hasattr(base_child, \"prefix\"):\n",
    "        base_child = base_child.children[0]\n",
    "    base_code_indent = base_child.prefix\n",
    "except:\n",
    "    print(\"error~!#\")\n",
    "# 注意，insert_body首行自带\\n\n",
    "insert_body = Utils.get_dead_if_body(self_lang_str, base_code_indent)\n",
    "random_case = random.randint(0, 1)\n",
    "if random_case == 0:\n",
    "    # 插入一个if true 的语句\n",
    "    new_body_string = (\n",
    "        f\"{base_code_indent}if True:\\n\"\n",
    "        + f\"{body_block_string}\\n\"\n",
    "        + f\"{base_code_indent}else:\"\n",
    "        + f\"{insert_body}\"\n",
    "    )\n",
    "else:\n",
    "    # 插入一个if false 的语句\n",
    "    new_body_string = (\n",
    "        f\"{base_code_indent}if False:\"\n",
    "        + f\"{insert_body}\\n\"\n",
    "        + f\"{base_code_indent}else:\\n\"\n",
    "        + f\"{body_block_string}\"\n",
    "    )\n",
    "\n",
    "# 最后和function的头部拼接起来\n",
    "prefix_string = PythonParsoParser.get_ast_prefix_string(func_node)\n",
    "\n",
    "\n",
    "new_code_string = prefix_string + new_body_string\n",
    "# print(new_code_string)\n",
    "# print(base_code_indent)\n",
    "print(prefix_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in tqdm(dataset):\n",
    "# for i in range(455,dataset.shape[0]):\n",
    "# row = dataset[i]\n",
    "for row in tqdm(dataset):\n",
    "    # 检查是否可以用同样的方法删去注释\n",
    "    code_string = row[\"code\"]\n",
    "    doc_string = row[\"docstring\"]\n",
    "    start_position = code_string.find(doc_string)\n",
    "    end_position = start_position + len(doc_string)\n",
    "    # try:\n",
    "    # 向后追溯，找到连续三个引号\"\"\"之后，再向后找到第一个\\n符号，这个\\n符号也要删去\n",
    "    while (\n",
    "        code_string[end_position : end_position + 3] != '\"\"\"'\n",
    "        and code_string[end_position : end_position + 3] != \"'''\"\n",
    "        and end_position + 3 < len(code_string)\n",
    "    ):\n",
    "        print(code_string[end_position : end_position + 3])\n",
    "        end_position += 1\n",
    "    if end_position + 3 >= len(code_string):\n",
    "        print(\"error~!\")\n",
    "        print(code_string)\n",
    "        break\n",
    "    while code_string[end_position] != \"\\n\":\n",
    "        end_position += 1\n",
    "    end_position += 1\n",
    "    try:\n",
    "        edit_block = code_string[end_position:]\n",
    "        # print(f'{Fore.BLUE}{code_string[0:end_position].encode()}{Fore.RED}{code_string[end_position:].encode()}{Style.RESET_ALL}')\n",
    "    except:\n",
    "        print(f\"error~!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parso Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n",
      "\t    rawurl = []\n",
      "\t    dom = parseString(xml_data)\n",
      "\t    for node in dom.getElementsByTagName('durl'):\n",
      "\t        url = node.getElementsByTagName('url')[0]\n",
      "\t        rawurl.append(url.childNodes[0].data)\n",
      "\t    return rawurl\n"
     ]
    }
   ],
   "source": [
    "import parso\n",
    "\n",
    "from process_data.RobustCodeSum import PythonParsoParser\n",
    "\n",
    "row = dataset[0]\n",
    "# print(row[\"code\"])\n",
    "code = row[\"code\"]\n",
    "parsed_ast = parso.parse(code, error_recovery=False, version=\"3.7\")\n",
    "code_tokens, comment_tokens = [], []\n",
    "\n",
    "func_nodes = list(parsed_ast.iter_funcdefs())\n",
    "\n",
    "func_node = func_nodes[0]\n",
    "doc_node = func_node.get_doc_node()\n",
    "\n",
    "body_block = PythonParsoParser.find_function_body_block(func_node)\n",
    "body_block_string = PythonParsoParser.get_body_block_string(body_block)\n",
    "# 每一行加一个\\t\n",
    "body_block_string = \"\\t\" + body_block_string.replace(\"\\n\", \"\\n\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试从输出位置load data文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14917, 12)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from datasets import load_dataset,load_from_disk\n",
    "\n",
    "reload_data = load_from_disk('../local_data/second/semantic/IRS/python/CSN')\n",
    "print(reload_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "async def renew_lock(self):\n",
    "    \"\"\"Renew the message lock.\n",
    "\n",
    "    This will maintain the lock on the message to ensure\n",
    "    it is not returned to the queue to be reprocessed. In order to complete (or otherwise settle)\n",
    "    the message, the lock must be maintained. Messages received via ReceiveAndDelete mode are not\n",
    "    locked, and therefore cannot be renewed. This operation can also be performed as an asynchronous\n",
    "    background task by registering the message with an `azure.servicebus.aio.AutoLockRenew` instance.\n",
    "    This operation is only available for non-sessionful messages.\n",
    "\n",
    "    :raises: TypeError if the message is sessionful.\n",
    "    :raises: ~azure.servicebus.common.errors.MessageLockExpired is message lock has already expired.\n",
    "    :raises: ~azure.servicebus.common.errors.SessionLockExpired if session lock has already expired.\n",
    "    :raises: ~azure.servicebus.common.errors.MessageAlreadySettled is message has already been settled.\n",
    "    \"\"\"\n",
    "    if hasattr(self._receiver, \"locked_until\"):\n",
    "        raise TypeError(\n",
    "            \"Session messages cannot be renewed. Please renew the Session lock instead.\"\n",
    "        )\n",
    "    self._is_live(\"renew\")\n",
    "    expiry = await self._receiver._renew_locks(\n",
    "        self.lock_token\n",
    "    )  # pylint: disable=protected-access\n",
    "    self._expiry = datetime.datetime.fromtimestamp(expiry[b\"expirations\"][0] / 1000.0)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
